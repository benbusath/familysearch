{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bottleneck' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6e27672767f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\ml-record-linking\\splycer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msplycer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_set\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRecordDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msplycer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairs_set\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPairsCOO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPairsMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msplycer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_engineer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeatureEngineer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msplycer\\record_set.pyx\u001b[0m in \u001b[0;36minit splycer.record_set\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from pandas.core.arrays.integer import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mInt16Dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mExtensionOpsMixin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    ExtensionScalarOpsMixin)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatetimeArray\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntervalArray\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoNewAttributesMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPandasObject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_shared_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccessor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDirNamesMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0m_shared_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mbottleneck\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     _BOTTLENECK_INSTALLED = (LooseVersion(ver) >=\n\u001b[0;32m     31\u001b[0m                              LooseVersion(_MIN_BOTTLENECK_VERSION))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bottleneck' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\ml-record-linking\\splycer')\n",
    "from splycer.record_set import RecordDataFrame\n",
    "from splycer.pairs_set import PairsCOO, PairsMatrix\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "from splycer.xgboost_match import XGBoostMatch\n",
    "from splycer.record_set import RecordDB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature engineer\n"
     ]
    }
   ],
   "source": [
    "print(\"creating feature engineer\")\n",
    "fe = FeatureEngineer()\n",
    "cols = [\"marstat\", \"race\", \"rel\", \"mbp\", \"fbp\", \"first_sdxn\", \"last_sdxn\", \"bp\", \"county\",\n",
    "        \"immigration\", \"birth_year\", [\"res_lat\", \"res_lon\"], [\"bp_lat\", \"bp_lon\"],\n",
    "        [f\"first_vec{i}\" for i in range(2, 202)], [f\"last_vec{i}\" for i in range(2,202)],\n",
    "        \"first\", \"last\",\n",
    "        \"first\", \"last\",\n",
    "        \"first\", \"last\",\n",
    "        \"first\", \"last\"\n",
    "       ]\n",
    "\n",
    "\n",
    "#similarity functions\n",
    "col_comps = [\"exact match\"] * 9\n",
    "col_comps.extend([\"abs dist\"] * 2)\n",
    "col_comps.extend([\"geo dist\"] * 2)\n",
    "col_comps.extend([\"euclidean dist\"] * 2)\n",
    "col_comps.extend([\"jw\"] * 2)\n",
    "col_comps.extend([\"trigram\"] * 2)\n",
    "col_comps.extend([\"bigram\"] * 2)\n",
    "col_comps.extend(['ngram'] * 2)\n",
    "#extra arguments\n",
    "col_args = list({} for i in range(5))\n",
    "col_args.extend([{\"comm_weight\": \"d\", \"comm_col\": \"first_comm\"}, {\"comm_weight\": \"d\", \"comm_col\": \"last_comm\"},\n",
    "                 {\"comm_weight\": \"d\", \"comm_col\": \"bp_comm\"}])\n",
    "col_args.extend(list({} for i in range(7)))\n",
    "col_args.extend([{\"comm_weight\": \"d\", \"comm_col\": \"first_comm\"}, {\"comm_weight\": \"d\", \"comm_col\": \"last_comm\"}] * 4)\n",
    "\n",
    "assert len(cols) == len(col_comps) == len(col_args)\n",
    "for i, j, k in zip(cols, col_comps, col_args):\n",
    "    fe.add_comparison(i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "n=100000\n",
    "chunk=10000\n",
    "conn = pyodbc.connect(\"DSN=rec_db\")\n",
    "print(\"Loading data...\")\n",
    "\n",
    "chunks = pd.read_sql(\"Select top 10000 * FROM Price.dbo.AA_training_data_1910_1920_large\", conn,chunksize=chunk)\n",
    "data=[]\n",
    "for chunk in tqdm(chunks):\n",
    "    data.append(chunk)\n",
    "df=pd.concat(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating pairs set\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Build record sets\n",
    "print(\"creating record set 1\")\n",
    "cols1910 = [s for s in df.columns if \"1910\" in s]\n",
    "df1910 = df[cols1910].drop_duplicates()\n",
    "df1910.columns = [s.replace(\"_1910\", \"\") for s in df1910.columns]\n",
    "record_set1 = RecordDataFrame(1910, df1910.set_index(\"index\", drop=True))\n",
    "del df1910\n",
    "\n",
    "print(\"creating record set 2\")\n",
    "cols1920 = [s for s in df.columns if \"1920\" in s and s != \"true_index_1920\"]\n",
    "df1920 = df[cols1920].drop_duplicates()\n",
    "df1920.columns = [s.replace(\"_1920\", \"\")for s in df1920.columns]\n",
    "record_set2 = RecordDataFrame(1920, df1920.set_index(\"index\", drop=True))\n",
    "del df1920\n",
    "'''\n",
    "\n",
    "# Build record sets\n",
    "record_set1=RecordDB(1910,'dbo.AA_training_data_1910_compiled','[index]','rec_db')\n",
    "record_set2=RecordDB(1920,'dbo.AA_training_data_1920_compiled','[index]','rec_db')\n",
    "\n",
    "# Build pairs sets\n",
    "print(\"creating pairs set\")\n",
    "uids1 = df[\"index_1910\"]\n",
    "uids2 = df[\"index_1920\"]\n",
    "is_match = (df[\"index_1920\"] == df[\"true_index_1920\"])\n",
    "\n",
    "# create holdout set for test validation\n",
    "idx=is_match.iloc[:178].index\n",
    "# create pairs set containing compares for the holdoutset only\n",
    "sample_pair_set=PairsCOO(1910,1920,uids1.iloc[idx],uids2.iloc[idx],is_match.iloc[idx])\n",
    "\n",
    "for frame in [uids1,uids2,is_match]:\n",
    "    # remove holdout set data from training data\n",
    "    frame.drop(idx,axis=0,inplace=True)\n",
    "    \n",
    "pairs_set = PairsCOO(1910, 1920, uids1, uids2, is_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import turbodbc\n",
    "import numpy as np\n",
    "import time\n",
    "maxsize=1000000\n",
    "nrows = sample_pair_set.ncompares\n",
    "if maxsize < sample_pair_set.ncompares:\n",
    "    nrows = maxsize\n",
    "uids1 = []\n",
    "uids2 = []\n",
    "labels = []\n",
    "i = 1\n",
    "for uid1, uid2, label in sample_pair_set:\n",
    "    uids1.append(uid1)\n",
    "    uids2.append(uid2)\n",
    "    labels.append(label)\n",
    "    if i > maxsize:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "extra_joins = \"\"\"\n",
    "self.cursor.execute(f\"select column_name from information_schema.columns where table_name = '{self.table_name}'\")\n",
    "cols = self.cursor.fetchall()\n",
    "self.cols = np.ndarray(len(cols), dtype=\"U50\")\n",
    "for i in range(len(cols)):\n",
    "    self.cols[i] = cols[i][0]\n",
    "\"\"\"\n",
    "table_name='dbo.AA_training_data_1910_compiled'\n",
    "idx_name='[index]'\n",
    "dsn='rec_db'\n",
    "conn = turbodbc.connect(dsn='rec_db', turbodbc_options=turbodbc.make_options(prefer_unicode=True))\n",
    "data = pd.read_sql(f\"select * from {table_name} where {idx_name} in {tuple(uids1)}\", conn)\n",
    "'''\n",
    "cursor=conn.cursor()\n",
    "cursor.execute(f\"select column_name from INFORMATION_SCHEMA.columns where table_name = '{table_name}'\")\n",
    "cols = self.cursor.fetchall()\n",
    "'''\n",
    "\n",
    "df1=record_set1.get_records(uids1)\n",
    "df2=record_set2.get_records(uids2)\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "def checkEqual(L1, L2):\n",
    "    return len(L1) == len(L2) and sorted(L1) == sorted(L2)\n",
    "checkEqual(df1.columns.values,df2.columns.values)\n",
    "#pairs1=uids1.values\n",
    "#pairs2=uids2.values\n",
    "\n",
    "'''\n",
    "for label in [\"marstat\", \"race\", \"rel\", \"mbp\", \"fbp\", \"first_sdxn\", \"last_sdxn\", \"bp\", \"county\", \"immigration\", \"birth_year\"]:\n",
    "    (df1[label] == df2[label]).mask(df1[label].isna() | df2[label].isna(), np.nan)\n",
    "'''\n",
    "record_set1.extra_joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set1=177 set2=178\n",
      "set1a=178 set2a=178\n"
     ]
    }
   ],
   "source": [
    "set1=set(df1['index'].tolist())\n",
    "set2=set(df2['index'].tolist())\n",
    "set1a=tuple(uids1)\n",
    "set2a=set(uids2)\n",
    "print(f'set1={len(set1)} set2={len(set2)}')\n",
    "print(f'set1a={len(set1a)} set2a={len(set2a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>marstat</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>household</th>\n",
       "      <th>immigration</th>\n",
       "      <th>race</th>\n",
       "      <th>rel</th>\n",
       "      <th>female</th>\n",
       "      <th>bp</th>\n",
       "      <th>mbp</th>\n",
       "      <th>...</th>\n",
       "      <th>last_vec192</th>\n",
       "      <th>last_vec193</th>\n",
       "      <th>last_vec194</th>\n",
       "      <th>last_vec195</th>\n",
       "      <th>last_vec196</th>\n",
       "      <th>last_vec197</th>\n",
       "      <th>last_vec198</th>\n",
       "      <th>last_vec199</th>\n",
       "      <th>last_vec200</th>\n",
       "      <th>last_vec201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9940583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1906</td>\n",
       "      <td>2484165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252548</td>\n",
       "      <td>0.182037</td>\n",
       "      <td>0.059878</td>\n",
       "      <td>0.537467</td>\n",
       "      <td>0.204997</td>\n",
       "      <td>-0.671293</td>\n",
       "      <td>-0.090781</td>\n",
       "      <td>-0.354124</td>\n",
       "      <td>0.127814</td>\n",
       "      <td>-0.386039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1910</td>\n",
       "      <td>71695.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031697</td>\n",
       "      <td>0.034178</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.088089</td>\n",
       "      <td>-0.271884</td>\n",
       "      <td>-0.149222</td>\n",
       "      <td>-0.500562</td>\n",
       "      <td>-0.688743</td>\n",
       "      <td>0.211320</td>\n",
       "      <td>-0.307028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24830219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1884</td>\n",
       "      <td>5704274.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277734</td>\n",
       "      <td>-0.054636</td>\n",
       "      <td>0.089288</td>\n",
       "      <td>0.266973</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>-0.363966</td>\n",
       "      <td>-0.109247</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>-0.282315</td>\n",
       "      <td>0.417428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77103589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1903</td>\n",
       "      <td>10317375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024284</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>-0.376699</td>\n",
       "      <td>-0.241264</td>\n",
       "      <td>-0.101558</td>\n",
       "      <td>-0.252486</td>\n",
       "      <td>0.175191</td>\n",
       "      <td>-0.277608</td>\n",
       "      <td>-0.089618</td>\n",
       "      <td>-0.485440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37617749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1857</td>\n",
       "      <td>19761904.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>-0.139591</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>-0.062933</td>\n",
       "      <td>-0.127447</td>\n",
       "      <td>-0.262847</td>\n",
       "      <td>0.217197</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.127425</td>\n",
       "      <td>-0.008389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  marstat  birth_year   household  immigration  race  rel  female  \\\n",
       "0   9940583      0.0        1906   2484165.0          NaN     1    3       1   \n",
       "1    240916      0.0        1910     71695.0          NaN     1    3       1   \n",
       "2  24830219      1.0        1884   5704274.0          NaN     1    1       1   \n",
       "3  77103589      0.0        1903  10317375.0          NaN     1    3       1   \n",
       "4  37617749      1.0        1857  19761904.0          NaN     1    1       1   \n",
       "\n",
       "   bp  mbp  ...  last_vec192  last_vec193  last_vec194  last_vec195  \\\n",
       "0  24   24  ...    -0.252548     0.182037     0.059878     0.537467   \n",
       "1   3    3  ...    -0.031697     0.034178     0.012270     0.088089   \n",
       "2  32   41  ...     0.277734    -0.054636     0.089288     0.266973   \n",
       "3  50   50  ...     0.024284     0.062866    -0.376699    -0.241264   \n",
       "4  65   65  ...     0.005522    -0.139591    -0.000388    -0.062933   \n",
       "\n",
       "   last_vec196  last_vec197  last_vec198  last_vec199  last_vec200  \\\n",
       "0     0.204997    -0.671293    -0.090781    -0.354124     0.127814   \n",
       "1    -0.271884    -0.149222    -0.500562    -0.688743     0.211320   \n",
       "2     0.161947    -0.363966    -0.109247    -0.009724    -0.282315   \n",
       "3    -0.101558    -0.252486     0.175191    -0.277608    -0.089618   \n",
       "4    -0.127447    -0.262847     0.217197    -0.001719    -0.127425   \n",
       "\n",
       "   last_vec201  \n",
       "0    -0.386039  \n",
       "1    -0.307028  \n",
       "2     0.417428  \n",
       "3    -0.485440  \n",
       "4    -0.008389  \n",
       "\n",
       "[5 rows x 429 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1.set_index('index').loc[uids1].reset_index()\n",
    "# df2.set_index('index').loc[uids2].reset_index()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-708e479b2e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"temp_model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "with open(f\"temp_model\", 'wb') as file:\n",
    "    pkl.dump(model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating xgb match object\n",
      "training\n",
      "creating training set...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d21b9c31b18a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxgb_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBoostMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_set1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_set2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_pair_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mxgb_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32msplycer\\xgboost_match.pyx\u001b[0m in \u001b[0;36msplycer.xgboost_match.XGBoostMatch.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msplycer\\xgboost_match.pyx\u001b[0m in \u001b[0;36msplycer.xgboost_match.XGBoostMatch.create_training_set\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msplycer\\feature_engineer.pyx\u001b[0m in \u001b[0;36msplycer.feature_engineer.FeatureEngineer.compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msplycer\\base.pyx\u001b[0m in \u001b[0;36msplycer.base.WeightedCompareBase.transform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msplycer\\comparisons.pyx\u001b[0m in \u001b[0;36msplycer.comparisons.BooleanMatch.compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mR:\\JoePriceResearch\\Python\\AnacondaNew\\envs\\ml_rec_env\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m             raise ValueError(\"Can only compare identically-labeled \"\n\u001b[0m\u001b[0;32m   1677\u001b[0m                              \"Series objects\")\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "#training initial model:\n",
    "model = XGBClassifier(n_estimators=2000, max_depth=3, learning_rate=.01, n_jobs=8,importance_type='gain')\n",
    "print(\"creating xgb match object\")\n",
    "xgb_trainer = XGBoostMatch(record_set1, record_set2, sample_pair_set, fe, model)\n",
    "print(\"training\")\n",
    "xgb_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalulate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "def evalulate(pair_set):\n",
    "    xgb_predictor=XGBoostMatch(record_set1,record_set2,pair_set,fe,model)\n",
    "    X,y=xgb_predictor.create_training_set()\n",
    "    y_pred = xgb_predictor.model.predict(X)\n",
    "    confusion_mat = confusion_matrix(y, y_pred)\n",
    "    test_precision = precision_score(y, y_pred)\n",
    "    test_recall = recall_score(y, y_pred)\n",
    "    return confusion_mat,test_precision,test_recall\n",
    "print(evalulate(sample_pair_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME fix save prediction results to txt file thing\n",
    "# located in XGBoostMatch class\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "xgb_predictor=XGBoostMatch(record_set1,record_set2,sample_pair_set,fe,model)\n",
    "xgb_predictor.run(f'AA_model_{today.strftime(\"%m-%d-%y\")}_sample_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "file_name=f'V:\\projects\\deep_learning\\AA_model\\AA_model_{today.strftime(\"%m-%d-%y\")}'\n",
    "pkl.dump(xgb_trainer.model, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: sparse data can't be used in logreg\n",
    "try:\n",
    "    import numpy as np\n",
    "    col_names=np.array([\"marstat\", \"race\", \"rel\", \"mbp\", \"fbp\", \"first_sdxn\", \"last_sdxn\", \"bp\", \"county\",\n",
    "            \"immigration\", \"birth_year\", 'res_lat_lon', 'bp_lat_lon',\n",
    "            'first_vec', 'last_vec',\n",
    "            \"first_jaro\", \"last_jaro\",\n",
    "            \"first_trigram_comm\", \"last_trigram_comm\",\n",
    "            \"first_bigram_comm\", \"last_bigram_comm\",\n",
    "            \"first_ngram_comm\", \"last_ngram_comm\"\n",
    "            ])\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X,y=xgb_match.create_training_set()\n",
    "    X=np.nan_to_num(X,0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=69)\n",
    "    log=LogisticRegression()\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "    log.fit(X_train,y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"number of training obs: {X.shape[0]},\\n\\\n",
    "            precision: {test_precision}, recall: {test_recall}\")\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
