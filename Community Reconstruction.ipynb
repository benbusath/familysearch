{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family Search Community Reconstruction Tutorial\n",
    "This notebook will demonstrate how to run the community reconstruction process from end-to-end. Ultimately, what community reconstruction does is it adds every nuclear family member in a census to FamilySearch with minimal overlap of data that already exists on the website. It does this through several requests made to the FamilySearch API.\n",
    "\n",
    "Also, for families that already exist on the tree, this process returns tree-extending hint urls for famillies that are only partially covered on the tree. This way volunteers can go in and add family members of people who already exist on the tree. \n",
    "\n",
    "First you will need to import your census file. This can be any subset of a census so long as it has the required variables:\n",
    "\n",
    "**ark_id | relationship to head | household id | first name | surname | sex | census date | residence place | birthdate | birth place**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ark1900</th>\n",
       "      <th>event_date</th>\n",
       "      <th>event_place</th>\n",
       "      <th>household_id</th>\n",
       "      <th>pr_birth_date</th>\n",
       "      <th>pr_birth_place</th>\n",
       "      <th>pr_name_gn</th>\n",
       "      <th>pr_name_surn</th>\n",
       "      <th>pr_relationship_code</th>\n",
       "      <th>pr_sex_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MQMC-111</td>\n",
       "      <td>1900</td>\n",
       "      <td>Precinct 37 &amp;amp; 41 Colorado Springs city War...</td>\n",
       "      <td>468.0</td>\n",
       "      <td>Aug 1858</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Vincin*</td>\n",
       "      <td>King</td>\n",
       "      <td>Head</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MQMC-112</td>\n",
       "      <td>1900</td>\n",
       "      <td>Precinct 37 &amp;amp; 41 Colorado Springs city War...</td>\n",
       "      <td>465.0</td>\n",
       "      <td>Oct 1863</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>E A</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Head</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MQMC-113</td>\n",
       "      <td>1900</td>\n",
       "      <td>Precinct 37 &amp;amp; 41 Colorado Springs city War...</td>\n",
       "      <td>460.0</td>\n",
       "      <td>Oct 1874</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Geo</td>\n",
       "      <td>Williams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MQMC-114</td>\n",
       "      <td>1900</td>\n",
       "      <td>Precinct 37 &amp;amp; 41 Colorado Springs city War...</td>\n",
       "      <td>461.0</td>\n",
       "      <td>Feb 1884</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Beulah</td>\n",
       "      <td>White</td>\n",
       "      <td>Daughter</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MQMC-115</td>\n",
       "      <td>1900</td>\n",
       "      <td>Precinct 37 &amp;amp; 41 Colorado Springs city War...</td>\n",
       "      <td>466.0</td>\n",
       "      <td>Dec 1868</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>L</td>\n",
       "      <td>Kirkpatrick</td>\n",
       "      <td>Head</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ark1900  event_date                                        event_place  \\\n",
       "0  MQMC-111        1900  Precinct 37 &amp; 41 Colorado Springs city War...   \n",
       "1  MQMC-112        1900  Precinct 37 &amp; 41 Colorado Springs city War...   \n",
       "2  MQMC-113        1900  Precinct 37 &amp; 41 Colorado Springs city War...   \n",
       "3  MQMC-114        1900  Precinct 37 &amp; 41 Colorado Springs city War...   \n",
       "4  MQMC-115        1900  Precinct 37 &amp; 41 Colorado Springs city War...   \n",
       "\n",
       "   household_id pr_birth_date pr_birth_place pr_name_gn pr_name_surn  \\\n",
       "0         468.0      Aug 1858   Pennsylvania    Vincin*         King   \n",
       "1         465.0      Oct 1863       Illinois        E A       Forbes   \n",
       "2         460.0      Oct 1874       Missouri        Geo     Williams   \n",
       "3         461.0      Feb 1884           Ohio     Beulah        White   \n",
       "4         466.0      Dec 1868       Illinois          L  Kirkpatrick   \n",
       "\n",
       "  pr_relationship_code pr_sex_code  \n",
       "0                 Head        Male  \n",
       "1                 Head        Male  \n",
       "2                  NaN        Male  \n",
       "3             Daughter      Female  \n",
       "4                 Head        Male  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('el_paso_census.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean Census Data\n",
    "\n",
    "Notice that the given name of the first person listed contains a asterisk. Be sure to filter out households containing people who have special characters in either their given or surname. We have steps in the pipeline to ensure these don't get added to the tree, but it is best to just filter these out in the master census file from the start. We also should take out people with any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name_filt=df['pr_name_gn'].str.contains('[!@#$%^&*(),?\":{}|<>]',regex=True).fillna(True)\n",
    "last_name_filt=df['pr_name_surn'].str.contains('[!@#$%^&*(),?\":{}|<>]',regex=True).fillna(True)\n",
    "\n",
    "bad_households=df[(first_name_filt)|(last_name_filt)]['household_id']\n",
    "\n",
    "# '~' operator means logical not -- thus this can ituitively be read as .notin(bad_households)\n",
    "df=df[~df['household_id'].isin(bad_households)]\n",
    "df.dropna(inplace=True) # drop people with null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also good practice to only keep households with more than one person, meaning we do not add singletons to the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filter with all duplicate households with more than one person dropped\n",
    "singletons=df['household_id'].drop_duplicates(keep=False)\n",
    "\n",
    "# keep those not in singleton filter we created\n",
    "df=df[~df['household_id'].isin(singletons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the master census should only contain nuclear family members. In the context of community reconstrction, we only actually care about the head of household, spouse of head, and children of head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['pr_relationship_code'].isin(['Head','Wife','Son','Daughter'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Attatched Pids\n",
    "\n",
    "Now that we have a cleaned census file to work with, we will find out how much of this census is already attatched to pids on FamilySearch. We do this by running the GetPidFromArk.py method on the arks in our master census file. \n",
    "\n",
    "This will take any set of arks and return a crosswalk between attatched arks and pids. Any arks from our master census not in this crosswalk are not on FamilySearch yet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 of 13266\n",
      "Average Time:\t        0.0062 Seconds\n",
      "Hours Remaining:\t0.02 Hours\n",
      "\n",
      "3600 of 13266\n",
      "Average Time:\t        0.0062 Seconds\n",
      "Hours Remaining:\t0.02 Hours\n",
      "\n",
      "5400 of 13266\n",
      "Average Time:\t        0.0074 Seconds\n",
      "Hours Remaining:\t0.03 Hours\n",
      "\n",
      "7200 of 13266\n",
      "Average Time:\t        0.0071 Seconds\n",
      "Hours Remaining:\t0.03 Hours\n",
      "\n",
      "9000 of 13266\n",
      "Average Time:\t        0.0071 Seconds\n",
      "Hours Remaining:\t0.03 Hours\n",
      "\n",
      "10800 of 13266\n",
      "Average Time:\t        0.0073 Seconds\n",
      "Hours Remaining:\t0.03 Hours\n",
      "\n",
      "12600 of 13266\n",
      "Average Time:\t        0.007 Seconds\n",
      "Hours Remaining:\t0.02 Hours\n",
      "\n",
      "\n",
      "PIDs Collected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ark</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MQMC-14C</td>\n",
       "      <td>MCLX-HTN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MQMC-149</td>\n",
       "      <td>LZZ6-3HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MQMC-179</td>\n",
       "      <td>GS2M-J13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MQMC-14V</td>\n",
       "      <td>LCJW-VRB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MQMC-14W</td>\n",
       "      <td>L6L8-G1B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ark       pid\n",
       "0  MQMC-14C  MCLX-HTN\n",
       "1  MQMC-149  LZZ6-3HK\n",
       "2  MQMC-179  GS2M-J13\n",
       "3  MQMC-14V  LCJW-VRB\n",
       "4  MQMC-14W  L6L8-G1B"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('R:/JoePriceResearch/Python/all_code')\n",
    "from FamilySearch1 import FamilySearch\n",
    "# below step is technically not necassary. You could just make the in file your census file (as long as it's cleaned).\n",
    "df[['ark1900']].to_csv('in.csv',index=False)\n",
    "fs=FamilySearch('benbusath','1254Castlecombe.',os.getcwd(),'in.csv','out.csv',auth=True)\n",
    "ark_pid_cw=fs.GetPidFromArk(ark_col=0)\n",
    "\n",
    "ark_pid_cw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_tree: \t5832\n",
      "on_census: \t13266\n"
     ]
    }
   ],
   "source": [
    "print('on_tree: \\t'+str(len(ark_pid_cw)))\n",
    "print('on_census: \\t'+str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a FamilySearch coverage rate of about 50% in this county. We should now save our ark-pid crosswalk as a csv into our working directory.\n",
    "\n",
    "It is important to determine which households have people on the tree, so let's merge the ark-pid crosswalk back with our original census file to get a household_id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ark_pid_cw.rename(columns={'ark':'ark1900'},inplace=True)\n",
    "ark_pid_cw=ark_pid_cw.merge(df[['ark1900','household_id']],on='ark1900')\n",
    "\n",
    "ark_pid_cw.to_csv('el_paso_ark_pid_cw.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this GetPidFromArk code on our master census file essentially gives us progress updates for how our coverage rates are improving.This should be a step that is continually repeated throughout the community reconstruction process as more and more people are added to the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Island Census\n",
    "\n",
    "An island census is the subset of people in our target census whose households contain no nuclear family members on FamilySearch. These are the households that we can later add to FamilySearch using our automated source linker. \n",
    "\n",
    "To create the island census, filter out any people with households_ids associated with our arks that are attatched to a pid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "island_census=df[~df['household_id'].isin(ark_pid_cw['household_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run Hint Cleaner\n",
    "We will now run the hint_cleaner code on our ark-pid crosswalk we created. hint_cleaner.py takes in any dataset with columns of arks and pids, and returns a dataframe of classified pid-hints from this crosswalk that is filtered down by household. You can read the documentation of hint_cleaner for more information on how this code works. This step will be much more important for sub-censuses that already have good FamilySearch coverage\n",
    "\n",
    "Status Classification Information:\n",
    "\tOutput for hint_cleaner function is a dataframe in the format 'ark | pid | status | url'\n",
    "\tThe status column contains the following classifications stored as strings:\n",
    "\t\t\n",
    "\t\tcomplete:\tArk-pid hint has already been matched in the source linker\n",
    "\t\t\n",
    "\t\tduplicate:\tHint ark is matched to pid other than hint pid given\n",
    "\n",
    "\t\ttree-ext:\tHint that adds a new person to family search\n",
    "\t\t\n",
    "\t\tnormal:\t\tBasically everything that isn't classified as one of the three above. Usually\n",
    "\t\t\t\ta pid hint that adds a census source to an already existing pid in FamilySearch.\n",
    "\t\t\t\tMay include tree-extending hints that were not successfully classified as such\n",
    "\t\t\t\tor other weird cases.\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'auth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d928b8cae1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhint_cleaner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhint_cleaner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcleaned_hints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhint_cleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mark_pid_cw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ark1900'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'benbusath'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1254Castlecombe.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcleaned_hints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mV:\\Python\\community_reconstruction\\hint_cleaner\\hint_cleaner.py\u001b[0m in \u001b[0;36mhint_cleaner\u001b[1;34m(ark, username, password, pid, year, status_file)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFamilySearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'in.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'out.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'auth'"
     ]
    }
   ],
   "source": [
    "sys.path.append(r'V:\\Python\\community_reconstruction\\hint_cleaner')\n",
    "from hint_cleaner import hint_cleaner\n",
    "\n",
    "cleaned_hints=hint_cleaner(ark_pid_cw[['ark1900','pid']],username='benbusath',password='1254Castlecombe.')\n",
    "cleaned_hints.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
